import 'package:http/http.dart' as http;

abstract class OpenAIDataSource {
  Future<String> transcribeAudio(String audioPath);
  Future<String> generateSummary(String transcript);
  Future<String> askQuestion(String question, String context);
}

class OpenAIDataSourceImpl implements OpenAIDataSource {
  final http.Client client;
  final String apiKey;
  
  OpenAIDataSourceImpl({http.Client? client, String? apiKey})
      : client = client ?? http.Client(),
        apiKey = apiKey ?? 'your_api_key_here';
  
  @override
  Future<String> transcribeAudio(String audioPath) async {
    // Mock implementation - in real app this would call OpenAI Whisper API
    await Future.delayed(const Duration(seconds: 2)); // Simulate API call
    return 'This is a mock transcript of the audio recording. In a real implementation, this would be generated by OpenAI Whisper API.';
  }
  
  @override
  Future<String> generateSummary(String transcript) async {
    // Mock implementation - in real app this would call OpenAI GPT API
    await Future.delayed(const Duration(seconds: 1)); // Simulate API call
    return 'This is a mock summary of the transcript. In a real implementation, this would be generated by OpenAI GPT API.';
  }
  
  @override
  Future<String> askQuestion(String question, String context) async {
    // Mock implementation - in real app this would call OpenAI GPT API
    await Future.delayed(const Duration(seconds: 1)); // Simulate API call
    return 'This is a mock answer to your question: "$question". In a real implementation, this would be generated by OpenAI GPT API based on the context provided.';
  }
}
